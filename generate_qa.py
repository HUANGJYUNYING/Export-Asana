import os
import sys
import json
import glob
import re
import yaml  # pip install pyyaml
from openai import AzureOpenAI
from dotenv import load_dotenv
import config

load_dotenv()

# è¨­å®šè·¯å¾‘
PROCESSED_DIR = config.PROCESSED_DIR
QA_OUTPUT_DIR = os.path.join(config.BASE_DIR, "qa_dataset")
os.makedirs(QA_OUTPUT_DIR, exist_ok=True)

# Azure Client
client = AzureOpenAI(
    api_key=config.AZURE_OPENAI_API_KEY,
    api_version=config.AZURE_OPENAI_API_VERSION,
    azure_endpoint=config.AZURE_OPENAI_ENDPOINT,
)


def extract_metadata_and_content(md_content):
    """
    åˆ†é›¢ Markdown çš„ YAML æª”é ­èˆ‡å…§æ–‡
    """
    # ç°¡å–® regex æŠ“å– --- ä¹‹é–“çš„å…§å®¹
    match = re.match(r"^---\n(.*?)\n---\n(.*)", md_content, re.DOTALL)
    if match:
        yaml_text = match.group(1)
        body = match.group(2)
        try:
            meta = yaml.safe_load(yaml_text)
            return meta, body
        except:
            return {}, md_content
    return {}, md_content


def generate_qa(md_content):
    """
    è¼¸å…¥ï¼šMarkdown å…¨æ–‡ (å«åœ–ç‰‡åˆ†æå…§å®¹)
    è¼¸å‡ºï¼šJSON ç‰©ä»¶ { "question": "...", "answer": "..." }
    """
    system_prompt = """
    ä½ æ˜¯ä¸€åä¼æ¥­çŸ¥è­˜åº« QA æ•´ç†å°ˆç”¨ AI åŠ©æ‰‹ï¼Œè² è²¬å°‡ Asana ä»»å‹™ç´€éŒ„ï¼ˆMarkdown æ ¼å¼ï¼‰ è½‰æ›ç‚ºçµæ§‹åŒ–ã€å¯å¯©è¨ˆã€å¯è¿½æº¯ä¾†æºçš„ Q&A è³‡æ–™ã€‚

    ä½ çš„æ ¸å¿ƒåŸå‰‡æ˜¯ï¼š
    åªæ•´ç†å·²ç™¼ç”Ÿèˆ‡å·²è¢«è­‰å¯¦çš„å…§å®¹ï¼Œä¸è£œå¯«ã€ä¸æ¨è«–ã€ä¸æ”¹å¯«ä½¿ç”¨è€…çš„å•é¡Œèªæ„ã€‚

    ä¸€ã€è¼¸å…¥è³‡æ–™ç†è§£

    Asana ä»»å‹™æè¿°ä¸­ï¼Œå·²åŒ…å«ä¸€ä»½çµæ§‹åŒ–çš„ä½¿ç”¨è€…å•é¡Œå›å ±è¡¨å–®ï¼Œæ ¼å¼å›ºå®šï¼Œå¯èƒ½åŒ…å«ï¼š

    - æå•äººç‡Ÿé‹å–®ä½  
    - æå•äººå§“å  
    - æå•äºº Line é¡¯ç¤ºåç¨±  
    - æå•äººè¯çµ¡é›»è©±  
    - æå•äººè¯çµ¡ä¿¡ç®±  
    - æå•äººå•é¡Œä¸»æ—¨  
    - æå•äººå•é¡Œå…§æ–‡  
    - Line å®¢æœå¹³å°é€£çµ  

    äºŒã€Questionï¼ˆQï¼‰ç”¢ç”Ÿè¦å‰‡ï¼ˆåš´æ ¼é–å®šï¼‰

    Question çš„å”¯ä¸€ä¾†æº

    åƒ…èƒ½ç”±ä»¥ä¸‹å…©å€‹æ¬„ä½çµ„æˆï¼š
    - æå•äººå•é¡Œä¸»æ—¨  
    - æå•äººå•é¡Œå…§æ–‡  

    çµ„æˆæ–¹å¼
    ç›´æ¥ä»¥ä»¥ä¸‹æ ¼å¼ä¸²æ¥ï¼š

    `<æå•äººå•é¡Œä¸»æ—¨> - <æå•äººå•é¡Œå…§æ–‡>`

    ä¸å¾—æ”¹å¯«èªæ„  
    ä¸å¾—è£œå……èƒŒæ™¯  
    ä¸å¾—èª¿æ•´å•é¡Œç¯„åœ  

    å…è¨±çš„æœ€å°è™•ç†ï¼ˆåƒ…é™æ ¼å¼ï¼‰
    - ç§»é™¤å¤šé¤˜ç©ºç™½æˆ–æ›è¡Œ  
    - ä¿®æ­£æ˜é¡¯çš„æ¨™é»éŒ¯èª¤  
    - ç¢ºä¿ç‚ºå–®ä¸€å¥å¯è®€çš„å•å¥  

    åš´æ ¼ç¦æ­¢
    - é‡æ–°æè¿°å•é¡Œ  
    - æ”¹å¯«æˆæ›´é€šç”¨çš„å•æ³•  
    - æ–°å¢ç³»çµ±åç¨±ã€æµç¨‹æˆ–é™åˆ¶æ¢ä»¶  
    - æ¨æ¸¬ä½¿ç”¨è€…å¯¦éš›æƒ³å•çš„ã€Œå»¶ä¼¸å•é¡Œã€  

    ğŸ“Œ åŸå‰‡ï¼š
    Question å¿…é ˆèˆ‡ä½¿ç”¨è€…åŸå§‹æå•èªæ„å®Œå…¨ä¸€è‡´ï¼Œå¯ä¸€å°ä¸€å›æº¯ã€‚

    ä¸‰ã€Answerï¼ˆAï¼‰ç”¢ç”Ÿè¦å‰‡

    Answer åƒ…èƒ½æ ¹æ“šä»¥ä¸‹å…§å®¹ç”¢ç”Ÿï¼š
    - è¨è«–ç´€éŒ„ï¼ˆStoriesï¼‰ä¸­å·²æ˜ç¢ºé”æˆå…±è­˜çš„çµè«–  
    - å­ä»»å‹™ä¸­å·²å®Œæˆä¸”å…·é«”çš„è™•ç†æ–¹å¼  
    - åœ–ç‰‡åˆ†æçµæœä¸­å·²å‡ºç¾çš„æ“ä½œæ­¥é©Ÿæˆ–åˆ¤æ–·çµæœ  

    Answer å¿…é ˆï¼š
    - æè¿°å¯¦éš›æ¡å–çš„è§£æ±ºæ–¹å¼æˆ–ç¢ºèªçµæœ  
    - ä½¿ç”¨ä¸­ç«‹ã€åˆ¶å¼ã€å¯æ“ä½œçš„æ–‡å­—  
    - ä¸åŒ…å«æ¨è«–æˆ–å‡è¨­  

    Answer ç¦æ­¢ï¼š
    - è£œå……ã€Œå¯èƒ½åŸå› ã€  
    - å»¶ä¼¸ã€Œå»ºè­°åšæ³•ã€  
    - åˆä½µå¤šç¨®æœªå®šè«–èªªæ³•  

    å››ã€Q&A æœ‰æ•ˆæ€§åˆ¤æ–·ï¼ˆä¸å¯å¦¥å”ï¼‰

    è‹¥ä»»å‹™æœ€çµ‚çµæœåƒ…åŒ…å«ä»¥ä¸‹ä»»ä¸€æƒ…æ³ï¼Œå¿…é ˆå›å‚³ `valid: false`ï¼š
    - åƒ…è¡¨ç¤ºç‹€æ…‹ï¼ˆå·²ä¿®æ­£ã€å·²å®Œæˆã€å·²çµæ¡ˆï¼‰  
    - åƒ…è¡¨ç¤ºæµç¨‹è½‰äº¤ï¼ˆå·²è½‰äº¤å…¶ä»–éƒ¨é–€ï¼‰  
    - åƒ…æœ‰ç¢ºèªæ€§å›è¦†ï¼ˆOKã€Doneï¼‰  
    - ç„¡ä»»ä½•å¯é‡è¤‡çš„æ“ä½œã€è¨­å®šæˆ–åˆ¤æ–·æ¢ä»¶  

    åˆ¤æ–·æ¨™æº–ï¼š
    è‹¥å…¶ä»–äººç„¡æ³•ä¾æ­¤å…§å®¹è‡ªè¡Œè™•ç†ç›¸åŒå•é¡Œï¼Œå‰‡ä¸å¾—ç”¢ç”Ÿ Q&Aã€‚

    äº”ã€å€‹äººè³‡æ–™èˆ‡æ•æ„Ÿè³‡è¨Šé®ç½©ï¼ˆé›™é‡é˜²ç·šï¼‰
    å³ä½¿ Question ä¾†è‡ªä½¿ç”¨è€…åŸæ–‡ï¼Œä»éœ€ç¢ºä¿è¼¸å‡ºçµæœä¸­ä¸æ®˜ç•™ä»»ä½•å€‹è³‡æˆ–æ•æ„Ÿè³‡è¨Šï¼š

    - äººå â†’ `[äººå“¡]`  
    - é›»è©± â†’ `[PHONE]`  
    - Email â†’ `[EMAIL]`  
    - å“¡å·¥ / å®¢æˆ¶ç·¨è™Ÿ â†’ `[USER_ID]`  
    - ä¿å–®è™Ÿç¢¼ã€æ¡ˆä»¶ç·¨è™Ÿã€äº¤æ˜“åºè™Ÿã€è­‰ç…§è™Ÿç¢¼ç­‰å…·å”¯ä¸€è­˜åˆ¥æ€§çš„ç·¨è™Ÿ â†’ `[REFERENCE_ID]`  
    - å…¶ä»–ç–‘ä¼¼æ•æ„Ÿè³‡è¨Š â†’ `[SENSITIVE_INFO]`  

    åŸå‰‡ï¼š
    å¯§å¯èª¤é®ï¼Œä¹Ÿä¸å¯æ¼é®

    å…­ã€åˆ†é¡èˆ‡æ¨™ç±¤

    - `category`ï¼šä¾å•é¡Œæœ¬è³ªæ¨æ¸¬åˆ†é¡ï¼ˆå¦‚ï¼šBMSã€æ¬Šé™ã€æµç¨‹ã€ç³»çµ±éŒ¯èª¤ï¼‰  

    - `tags`ï¼š  
        - 2â€“5 å€‹é—œéµå­—  
        - åªä½¿ç”¨ä»»å‹™ä¸­å·²å‡ºç¾çš„è©å½™  
        - ä¸æ–°å¢æ¨æ¸¬æ€§é—œéµå­—  

    ä¸ƒã€è¼¸å‡ºæ ¼å¼ï¼ˆJSON Modeï¼Œåš´æ ¼éµå®ˆï¼‰

    æœ‰æ•ˆ Q&Aï¼š
    ```json
    {
    "valid": true,
    "question": "æå•äººå•é¡Œä¸»æ—¨ - æå•äººå•é¡Œå…§æ–‡",
    "answer": "ä¾ä»»å‹™ç´€éŒ„æ•´ç†å‡ºçš„æœ€çµ‚è™•ç†æ–¹å¼",
    "category": "å•é¡Œåˆ†é¡",
    "tags": ["é—œéµå­—1", "é—œéµå­—2"]
    }

    ç„¡æ•ˆ Q&Aï¼š
    ```json
    {
    "valid": false
    }

    """

    try:
        response = client.chat.completions.create(
            model=config.AZURE_OPENAI_CHAT_DEPLOYMENT,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": md_content},
            ],
            response_format={"type": "json_object"},
            temperature=0.3,
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        print(f"âŒ QA ç”Ÿæˆå¤±æ•—: {e}")
        return None


def run_qa_generation(target_proj_name=None):
    """
    Args:
        target_proj_name (str): è‹¥æœ‰æŒ‡å®šï¼Œåªè™•ç†è©²å°ˆæ¡ˆï¼›å¦å‰‡è™•ç†å…¨éƒ¨ã€‚
    """
    if not config.ENABLE_LLM_ANALYSIS:
        print("âš ï¸ LLM åˆ†æåŠŸèƒ½æœªé–‹å•Ÿï¼Œè·³é QA ç”Ÿæˆã€‚")
        return

    # æœå°‹ä¾†æº
    if target_proj_name:
        search_path = os.path.join(config.PROCESSED_DIR, target_proj_name, "**", "*.md")
    else:
        search_path = os.path.join(config.PROCESSED_DIR, "**", "*.md")

    md_files = glob.glob(search_path, recursive=True)
    if not md_files:
        print("âŒ æ‰¾ä¸åˆ°ä¾†æºæ–‡ä»¶ã€‚")
        return

    print(f"\nğŸš€ [Stage 3] QA ç”Ÿæˆä¸­ (å…± {len(md_files)} æª”)...")

    for i, fpath in enumerate(md_files):
        # é¡¯ç¤ºé€²åº¦
        sys.stdout.write(f"\r   è™•ç†ä¸­ ({i+1}/{len(md_files)})...")
        sys.stdout.flush()

        with open(fpath, "r", encoding="utf-8") as f:
            raw_content = f.read()

        # 1. æå– Metadata (ç‚ºäº†ç¹¼æ‰¿ expiry_date)
        meta, body = extract_metadata_and_content(raw_content)

        # ç°¡å–®éæ¿¾ï¼šå¦‚æœæ²’æœ‰ meta æˆ–æœªå®Œæˆï¼Œè·³é
        if not meta or meta.get("status") != "completed":
            continue

        # 2. ç”Ÿæˆ QA
        qa_result = generate_qa(body)

        if qa_result and qa_result.get("valid"):
            # 3. æº–å‚™å­˜æª”è·¯å¾‘
            rel_path = os.path.relpath(fpath, config.PROCESSED_DIR)
            save_path = os.path.join(config.QA_DIR, rel_path)

            os.makedirs(os.path.dirname(save_path), exist_ok=True)

            # 4. è£½ä½œ QA Markdown (å« Metadata)
            qa_md_lines = [
                "---",
                "type: qa_pair",
                f"source_gid: {meta.get('gid')}",
                f"title: \"{meta.get('title')}\"",
                f"created_date: {meta.get('created_date')}",
                f"expiry_date: {meta.get('expiry_date')}",
                f"section: \"{meta.get('section')}\"",
                "---",
                "\n",
                f"# â“ {qa_result['question']}",
                "\n",
                f"## ğŸ’¡ è§£ç­”",
                f"{qa_result['answer']}",
                "\n",
                f"## ğŸ·ï¸ æ¨™ç±¤",
                f"{', '.join(qa_result.get('tags', []))}",
                "\n",
                f"> [æŸ¥çœ‹åŸå§‹æ–‡ä»¶](../../processed_data/{rel_path.replace(os.sep, '/')})",
            ]

            with open(save_path, "w", encoding="utf-8") as f:
                f.write("\n".join(qa_md_lines))

    print(f"\nâœ… QA ç”Ÿæˆå®Œæˆï¼å„²å­˜æ–¼: {config.QA_DIR}")


if __name__ == "__main__":
    # ç¨ç«‹åŸ·è¡Œæ™‚ä¸æŒ‡å®šå°ˆæ¡ˆï¼Œè·‘å…¨é‡
    run_qa_generation()
